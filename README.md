# TSOTSALLM: Large Language Models at large scales
Large Language Models (LLMs) have made a new waive in Artificial Intelligence. Used by software giants, they are regarded as key enablers in various domains such as education, medicine, etc. Given the computational resources and the training time, their use is currently unattainable for the majority of companies and private users. In fact, their development and maintenance is currently only possible for large organizations able to afford the corresponding costs. 

In developing countries particularly where LLMs can be used to foster the development as well as attaining the Sustainable Development Goals, this technology is almost inaccessible to researchers, students and start-ups. In these countries, many researchers use their computers to build AI models. For instance, in a recent work, we combined several computers for annotating tabular datasets using Knowledge Graphs \cite{}. Even if this work got accepted at SemTab@ISWC, we were not able to run our model on the overall datasets and we did not get good evaluations.

TSOTSALLM aims to scale LLMS, making them accessible to researchers, students and a wide audience of companies of all sizes, particularly to people from developing countries. Thus, this work aims to provide methodologies and scale LLMS to be accessible to a wide audience of users globally.

## Research methodology
